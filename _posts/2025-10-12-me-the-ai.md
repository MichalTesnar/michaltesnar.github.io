---
layout: post
title: "Professional Impairment: Seeing Your Own Life Through the Lense of Artificial Intelligence"
date: 2025-10-12 14:00:00
description: Learning about machine learning makes me learn about myself.
categories: opinions
---

Although not a professional expert, it's fair to say I've spent some time learning about AI. Honestly, it all started with YouTube binges; that's when I realized I wanted to learn more about all of this and maybe even contribute. Then I happened to follow a bachelor's degree in the area of Artificial Intelligence, and am now currently pursuing my Master's, even though that goes more towards the mathematical theory and practical side of machine learning. Crazily enough, the hype around the area has only increased since the moment I started being interested in it. I've really had the wonderful luck of experiencing this growth first-hand. It is insane to see how much further we've moved in just a few years.

Since I started to learn about AI in 2021/2022, I've been on a long journey. In some way I am much further, I've certainly learned a lot about programming, training models, and the intricacies of mathematics connected to all of it. However, in some way, I'm still the same. I still get my breath taken away by talks on this topic (my newest discovery being [Blaise Aguera y Arcas](https://www.youtube.com/watch?v=OD5UzhaDWfg), I love listening to this guy). It's still super exciting to read a good paper about a new concept or a view on AI (which there is at least one good one a day). Even more, I enjoy spending some time pondering where this technology will take us in the upcoming years, and how it will change our society. In those regards, I still feel like a curious little child.

However, one might say that I sometimes push it too far, and nerd out too much. I love to talk about machine learning in my own life, and from time to time, I think about my life in terms of AI. It's not a unique thing to project concepts from science to personal life, nor into your philosophical point of view on the world. I have a vague memory from undergrad where we learned about how with the development of computers scientists started to see humans as modular machines (CPU = processing of the brain, RAM = memory of the brain, etc.) (one can argue that this actually goes both ways and yes, that is true: computers were developed to mimic human capabilities, but still the point stands). In reverse, we like to project our human concepts onto machines, e.g., the current transformer architecture behind ChatGPT has something called an "attention". What is more, all great scientists, like Turing or Einstein, seem to have philosophical depth to their findings, so maybe it's all just a sign of greatness that I think about this.

Either way, I wanted to share a few concepts of where I think machine learning meets my daily reality, and maybe some takeaways that one can derive from it. If you have never come across these technical terms, some (many) of the things will not make sense. I will try to explain everything from scratch as much as possible, but I already apologize if I didn't succeed.

## Part 1: My brain is a neural network.

Might seem obvious: our brains are in the end made of neurons, which is what has inspired the neural architectures. What is remarkable is to treat yourself as you would treat a neural network.

- Do you need to learn something? Supply yourself with as many input-output pairs as possible, and cycle through them many times.
- Are you mad at yourself that you forgot something? Don't be. Learning a new thing means forgetting another one; in machine learning we call it **'catastrophic forgetting'** and it happens all the time.

That really aligns with how I see myself learning, but maybe I'm too influenced by what I study.

## Part 2: I am a reinforcement learning agent.

We've seen AI lately get good at games like chess, or other interactive games. This area is called **reinforcement learning**, and it uses a reward signal to motivate agents to succeed in environments. Interestingly, humans are also such an agent! Our reward? **Dopamine**. We get rewarded when we feel successful, when we've done something right, and we don't get any if we fail to complete our tasks.

Closely connected to this is the notion of a **discount**: How much do you value a reward in the future as opposed to now? Are you willing to make a certain sacrifice to get more in the future and by how much? This is what discount controls. It is generally regarded that higher discount factors (meaning you sacrifice more for the future) are better for [success in life](https://en.wikipedia.org/wiki/Stanford_marshmallow_experiment).

Finally, every agent finds itself in an environment that is unknown to it. It doesn't know what actions lead to a better outcome, and which do not. Therefore it has to explore new actions. However, it doesn't know if the actions it has already found are optimal; therefore it also needs to exploit the currently available options. This is known as the **exploration / exploitation trade-off**.

## Part 3: We are all just part of a distribution.

Most people are average in most things, but exceptional in few. Some skills and abilities are correlated with others, while others are rather anti-correlated. And this reminds me of a randomly sampled vector from a Gaussian distribution. Everyone of us is basically sampled from a distribution of all people, and the role of learning about oneself is to apply **principal component analysis** to find out what components you are made of.

One other place where I see distributions playing a huge role are opportunities in life. To find out what life is about, one should sample the distribution. Go out, and sample experiences, and try to find the place that feels the best.

## Part 4: Life is an optimization process.

Lastly, when you set an AI model to run, you basically initiate a whole optimization process. And actually, the whole life sometimes feels like one big optimization process. As if everyone of us was actually an **optimizer**. We make steps in directions where we feel like we are going to do better.

However, one should not make big steps (changing everything in one day) but rather work on making small steps in a direction. This is like **gradient clipping**, where one regulates the amount of change on each step to ensure stability of the learning process.

Finally, I observed that actually one should change the learning rate, sometimes make a big change and then make more smaller changes later. That is exactly like the **cosine scheduler**, which helps modern models find the optima.

## Conclusion

If you made it here, you might be thinking: "Wow, Michal is really loosing it at this point." Or maybe I'm just finding it; maybe I just internalized the concepts to the point where they are not leaving me for life. We will see whether that is a good or bad thing, but I hope these new paradigms of thinking about intelligence will push humanity further towards a better understanding of itself.

I'm currently particularly excited about the movement sparked by Francois Chollet's [On the Measure of Intelligence](https://arxiv.org/pdf/1911.01547), which pushes AI researchers to consider new paradigms of intelligence. We already live in a world where computers can remember or look up better than we do.

Keep in mind that the ideas that you hear here brought us computers that talk to us. This is insane.

