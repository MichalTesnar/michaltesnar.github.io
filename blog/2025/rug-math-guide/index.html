<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> What Math do I Need for AI? Catch-Up Guide for RUG AI Undergrads | michal tešnar </title> <meta name="author" content="michal tešnar"> <meta name="description" content="Compression of knowledge of a recent graduate."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://michaltesnar.github.io/blog/2025/rug-math-guide/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">michal</span> tešnar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">What Math do I Need for AI? Catch-Up Guide for RUG AI Undergrads</h1> <p class="post-meta"> Created on March 15, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/category/guides"> <i class="fa-solid fa-tag fa-sm"></i> guides</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="introduction">Introduction</h2> <p>“So why did you choose Groningen?” A question that I have been asked multiple times after disclosing I study or studied there. The answer was “There is a unique program in AI.” Now, almost a year after finishing the program I am reflecting more and more about what the program gave me. More and more I come to realize how much breadth was explored, learning about philosophy, cognitive psychology, and biology of the brain is not what most CS undergrads can flex with. However, as the field of machine learning is not stopping to grow, I myself as a student of that program had found out that the depth of the knowledge is insufficient to gain a deep understanding of the material at hand, to read papers and maybe even contribute to the research in a meaningful way. I mean, test yourself right now.</p> <h3 id="linear-regression">Linear regression</h3> <p>(Sorry I broke LaTeX, working on fixing it, hopefully you can still orient yourself here.)</p> <p>The simplest model in ML for modeling relations relates targets <code class="language-plaintext highlighter-rouge">y</code> (an n-dimensional vector) with design matrix <code class="language-plaintext highlighter-rouge">X</code> (an n by d matrix) through vector <code class="language-plaintext highlighter-rouge">β</code> (a d-dimensional vector) with some Gaussian noise <code class="language-plaintext highlighter-rouge">w</code> added.</p> <p>y = X * β + w</p> <p>We can see that <code class="language-plaintext highlighter-rouge">β̂ = (X&lt;sup&gt;T&lt;/sup&gt; * X)&lt;sup&gt;-1&lt;/sup&gt; * X&lt;sup&gt;T&lt;/sup&gt; * y</code> is an unbiased estimator of <code class="language-plaintext highlighter-rouge">β</code> using <code class="language-plaintext highlighter-rouge">E[w] = 0</code>:</p> <p>E[(X<sup>T</sup> * X)<sup>-1</sup> * X<sup>T</sup> * y] = E[(X<sup>T</sup> * X)<sup>-1</sup> * X<sup>T</sup> * (X * β + w)] = (X<sup>T</sup> * X)<sup>-1</sup> * X<sup>T</sup> * X * β = β</p> <p>Finally, <code class="language-plaintext highlighter-rouge">β̂</code> is also the least-squares estimator, for which we can prove this error bound.</p> <table> <tbody> <tr> <td>E[</td> <td> </td> <td>β̂ - β</td> <td> </td> <td> <sup>2</sup>] = σ<sup>2</sup> * (d / n)</td> </tr> </tbody> </table> <p><em>Remark:</em> The least squares is a convex function so there is a unique minimum which can be found in polynomial time using gradient descent.</p> <h3 id="wait-what">Wait what?</h3> <p>So, how did reading this feel? No, I am not trying to discourage you here and gatekeep machine learning knowledge from you! This is literally taken from the first chapter of my <a href="https://lecturenotes.cope.ethz.ch/alg4ds/spring25/A001/home.html" rel="external nofollow noopener" target="_blank">master’s course</a>, and except for the last theorem I have not left out any extra explanations.</p> <p>When I was in my second year taking <em>Introduction to Machine Learning</em>, I was not able to read this fluently and make sense out of it. I am putting this mildly, cause I do not want to presume what your level is, maybe you are just fine. But I was genuinely intimidated when I saw the closed form solution for linear regression. God, I had no clue what those weird brackets ($| \cdot |$) really meant, and that double $\mathbb{E}$ somebody told me was an <em>expectation</em>. The expression <em>gradient descent</em> I knew from pictures of colorful loss landscapes but did not know what it really was and <em>polynomial time</em> was not really my biggest friend either.</p> <p>The truth is in ML, as in any other branch, math is just a language we use to describe abstract objects we talk about (If you want to get philosophical I recommend reading <a href="https://www.maths.ed.ac.uk/~v1ranick/papers/wigner.pdf" rel="external nofollow noopener" target="_blank">The unreasonable effectiveness of mathematics in the natural sciences by Wigner</a>).</p> <p>If you want to understand what it is really about you need to get fluent in this language. It takes some time, but it is worth it (my journey is far from done, but I am way further than I was in my first year of BSc AI). To help you on the journey, you can enroll in any of the BSc Mathematics courses. They have great tradition and are (mostly well taught). Here, I establish a list of courses that are relevant, and I try to give a bit of context why (in my humble opinion).</p> <h2 id="essential-tier">Essential Tier</h2> <p>These courses will help you obtain sufficient mathematical dexterity (credits to Andrei Girjoaba for this naming) to read mathematical texts and understand the ideas behind them. For your convenience I have added links to Ocasys, where you can view more information.</p> <p><strong>IMPORTANT DISCLAIMER</strong>: THESE COURSES DO NOT COVER THE SAME STUFF AS THE COURSES IN AI CURRICULUM CALLED ‘FOR AI’. I cannot understate this, you will be challenged way more. Even if you passed ‘Linear Algebra and Multivariable Calculus for AI’ with a 10, you will get challenged in both Linear Algebra and Calculus for Math. This is true especially for Statistics for Math, which covers completely different things than AI Statistics.</p> <ul> <li> <a href="https://ocasys.rug.nl/current/catalog/course/WBMA020-05" rel="external nofollow noopener" target="_blank"><strong>Linear Algebra I</strong></a>: Essential for understanding spectral decomposition and the idea of subspaces. This is needed for understanding dimensionality reduction techniques like PCA, which are at the core of machine learning. As a plus, this course is introductory and it teaches proof techniques such as proof by contradiction, which is useful if you haven’t done that in the past.</li> <li> <a href="https://ocasys.rug.nl/current/catalog/course/WBMA035-05" rel="external nofollow noopener" target="_blank"><strong>Linear Algebra II</strong></a>: Essential for understanding singular value decomposition, which is also one of the essential mathematical tools. The latest example of usage is in understanding vanishing and exploding gradients phenomena of RNNs.</li> <li> <a href="https://ocasys.rug.nl/current/catalog/course/WBMA029-05" rel="external nofollow noopener" target="_blank"><strong>Calculus II</strong></a>: Gradient is one of the main topics. This will be your best friend if you ever want to train a neural net. Hand in hand with it goes chain rule. If you do not trust me it is important, try to explain backpropagation without it. (You might want to take <a href="https://ocasys.rug.nl/current/catalog/course/WBMA003-05" rel="external nofollow noopener" target="_blank"><strong>Calculus I</strong></a> before if you do not trust yourself too much with your math skills, I have not done it myself and managed, but honestly I still struggle a bit with things like Fourier Series that are treated there)</li> <li> <a href="https://ocasys.rug.nl/current/catalog/course/WBMA046-05" rel="external nofollow noopener" target="_blank"><strong>Probability Theory</strong></a>: Expectation, variance, probability distribution. Trust me, this is a must. The notions are not that difficult once profoundly understood, but this hard course is definitely worth the pain. Highly recommended.</li> <li> <a href="https://ocasys.rug.nl/current/catalog/course/WBMA009-05" rel="external nofollow noopener" target="_blank"><strong>Statistics</strong></a>: ML is just Stats on steroids. Estimators play the main role in this course. The word likelihood finally started making sense to me in this course too. Finally, you also get insight into p-values and confidence intervals. Priceless.</li> <li>(Editor’s Pick) <a href="https://ocasys.rug.nl/current/catalog/course/WBMA012-05" rel="external nofollow noopener" target="_blank"><strong>Analysis</strong></a>: Alef Sterk is one of the best lecturers that I have encountered so far, and even though this course does not directly contribute to ML understanding I still recommend it cause it gives you a stronger basis. You get better at proving and in mathematical thinking.</li> </ul> <h2 id="pro-tier">Pro Tier</h2> <p>This is the list of courses ‘I wish I have done’. These are more advanced (=mostly 2nd year math) courses that give you background insight into what is going on in ML. They are not essential, but check them out and if any of the theory seems appealing then certainly go for it. They are all relevant for different areas of ML.</p> <ul> <li> <a href="https://ocasys.rug.nl/current/catalog/course/WBMA024-05" rel="external nofollow noopener" target="_blank"><strong>Probability and Measure</strong></a>: If you want to go more into depth into Probability Theory, this is a course that you want. This gives you the technical background for that (didn’t take this one).</li> <li> <a href="https://ocasys.rug.nl/current/catalog/course/WBMA054-05" rel="external nofollow noopener" target="_blank"><strong>Introduction to Optimization</strong></a>: Keyword <em>gradient descent</em>. Optimization is key for training neural nets. This course goes a wee bit too deep, but the first half is definitely relevant.</li> <li> <a href="http://ocasys.rug.nl/current/catalog/course/WBMA033-05" rel="external nofollow noopener" target="_blank"><strong>Functional Analysis</strong></a>: AKA Linear Algebra III, teaches you more about linear operators and functionals. Very good stuff. Also by Alef Sterk.</li> <li> <a href="https://ocasys.rug.nl/current/catalog/course/WBMA031-05" rel="external nofollow noopener" target="_blank"><strong>Dynamical Systems</strong></a>: Recurrent neural networks are modeling dynamical systems, this course will help you appreciate that better (didn’t take this one).</li> <li> <a href="https://ocasys.rug.nl/current/catalog/course/WBMA036-05" rel="external nofollow noopener" target="_blank"><strong>Metric and Topological Spaces</strong></a>: Reinforcement Learning needs this. Without fixed point theorem, how does the fact that Bellman operator is a contraction help you? (Didn’t take this one).</li> <li> <a href="https://ocasys.rug.nl/current/catalog/course/WBMA022-05" rel="external nofollow noopener" target="_blank"><strong>Multivariable Analysis</strong></a>: Keyword <em>manifold</em>, these mythical mathematical objects pop up in learning theory from time to time. Maybe it is a stretch, but could also come in handy (didn’t take this one).</li> </ul> <h2 id="closing">Closing</h2> <p>Doing mathematics is like eating vegetables. I am not saying you have to do it, some people do without it and they are doing just fine. But it certainly helps, and I think that if you read into some papers before and after taking the courses that I suggest, you will have a completely different experience with them! (And passing courses like ‘Neural Networks’ will be a breeze.)</p> <p>And no, these courses will neither teach you that you should normalize your input when training a neural net nor explain what torch dataloader is. Anyway, let me know if this was helpful and if you have courses that you would like to add to the list or if you completely disagree with my perspective.</p> <p>And do not forget, if you have any questions the study advisors usually know the best, and they are very helpful, so do not hesitate to talk to them. Personally, they have helped a whole lot during my studies!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/novy-byt/">Domov číslo čtyři</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/moving-to-zurich/">Moving to Zurich: A Little Guide to Attacking the Housing Market</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/true-difficulty-of-language-learning/">The True Difficulty of Language Learning: When Things Are Not The Way They Seem</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/collective-hysteria/">First Exam Season at ETH: A Collective Hysteria</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/quitting-llms/">Why I am Quitting ChatGPT: and Why You Should Too</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 michal tešnar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>